services:
    kafka:
        image: apache/kafka:3.8.1
        environment:
            KAFKA_NODE_ID: 1
            KAFKA_PROCESS_ROLES: broker,controller
            KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
            KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
            KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            KAFKA_NUM_PARTITIONS: 3
        healthcheck:
            test: /opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 || exit 1
            interval: 2s
            start_interval: 2s
            retries: 10
        networks:
            - kafka-network

    kafka-init-topics:
        image: apache/kafka:3.8.1
        depends_on:
            kafka:
                condition: service_healthy
        entrypoint: ["/bin/sh", "-c"]
        command: |
            /opt/kafka/bin/kafka-topics.sh --create --topic trade-events --partitions 1 --replication-factor 1 --bootstrap-server kafka:9092
            /opt/kafka/bin/kafka-topics.sh --create --topic topic1 --partitions 1 --replication-factor 1 --bootstrap-server kafka:9092

    data_producer:
        image: data_producer
        depends_on:
            - kafka-init-topics
        build:
            context: data_producer
            dockerfile: Dockerfile
        environment:
            SPEED_FACTOR: 5
            CSV_PATH: /data/debs2022-gc-trading-day-12-11-21.csv
            PRINT_SENT_RECORDS: true
        volumes:
            - ./data:/data
        networks:
            - kafka-network
    data_analyzer:
        image: data_analyzer
        depends_on:
            - spark-master
            - data_producer
        build:
            context: data_analyzer
            dockerfile: Dockerfile
        volumes:
            - ./data:/data
        networks:
            - kafka-network

    spark-master:
        image: bde2020/spark-master:3.3.0-hadoop3.3
        container_name: spark-master
        ports:
            - "8080:8080" # Spark Web UI
            - "7077:7077" # Spark Master Port
        environment:
            - INIT_DAEMON_STEP=setup_spark
        networks:
            - kafka-network

    spark-worker-1:
        image: bde2020/spark-worker:3.3.0-hadoop3.3
        container_name: spark-worker-1
        depends_on:
            - spark-master
        ports:
            - "8081:8081" # Spark Worker UI
        environment:
            - SPARK_MASTER=spark://spark-master:7077
        networks:
            - kafka-network

    influxdb:
        image: influxdb:2.7
        environment:
            - INFLUXDB_DB=mydb # Initial database name
            - INFLUXDB_ADMIN_USER=admin # Admin username
            - INFLUXDB_ADMIN_PASSWORD=admin_password # Admin password
        ports:
            - "8086:8086" # InfluxDB default port
        volumes:
            - influxdb-storage:/var/lib/influxdb
        networks:
            - kafka-network

    latencylogger:
        image: latency_logger
        environment:
            - TOPIC_NAME=topic1
        depends_on:
            - kafka-init-topics
        build:
            context: latency_logger
            dockerfile: Dockerfile
        volumes:
            - ./logs:/logs
        networks:
            - kafka-network

volumes:
    influxdb-storage:

networks:
    kafka-network:
        driver: bridge
